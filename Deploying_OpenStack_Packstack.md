---layout: docs_pagetitle: Deploying F5 OpenStack with Packstackurl: {{ page.title | slugify }}categories: openstack, testing, tools, Packstack, quickstarttags: red hat 7; centos 7; Packstack; BIG-IP VE 11.6.0;resource: true---<div class="alert alert-danger alert-dismissible" role="alert">    <button type="button" class="close" data-dismiss="alert" aria-label="Close"><span aria-hidden="true">&times;</span>    </button>    <strong>Heads up!</strong> This doc is under development.</div># IntroductionThis document provides instructions that will allow you to build a reference implementation of OpenStack that includes integration with F5® Networks technology. We've provided automation scripts and enhancements to existing installers -- [Packstack](https://wiki.openstack.org/wiki/Packstack) and [MaaS](http://www.ubuntu.com/cloud/maas) -- that can be used for continuous integration, deployment, and testing.## Packstack or MaaS: Which is right for me?[Packstack](https://wiki.openstack.org/wiki/Packstack) is supported for CentOS and Red Hat. [MaaS](http://www.ubuntu.com/cloud/maas)/[JuJu](https://jujucharms.com/) is supported for Ubuntu.Packstack is the simplest way to get OpenStack up and running with F5 technologies. It provides a good way to deploy and test a specific OpenStack environment and **can work with only one machine**.MaaS/Juju can be used as a more permanent test harness that can automatically install OpenStack onto bare metal via PXE boot and can run unattended and continuously. This more powerful option takes much more effort to set up and requires a **minimum of three** physical machines.The big operational difference between the two is that while Packstack assumes you have already installed the operating system, MaaS can automatically install it for you. MaaS can automatically deploy a variety of OpenStack environments in different configurations from bare metal; Packstack can only automatically deploy one OpenStack configuration.**If you require a simpler, resource-light, Red Hat/CentOS-compatible solution, please continue with this guide.****If you require a more complex, fully-automatable, resource-intensive, Ubuntu-compatible solution, please see [Deploying F5 OpenStack with MaaS/JuJu](#).**## Network OverviewEvery OpenStack configuration includes an “external”, or “public”, network. This network has a range of IP addresses that encompasses the local/management IP; floating IPs used for BIG-IP and VM instances;  gateway IPs for OpenStack routers attached to the external network; etc. Depending on your resources and needs, you may wish to use the QuickStart option, which requires only a single machine and a single routable IP address, or to go with a more complicated -- but more realistic -- configuration. An example of the latter would include a control server, a network gateway, and multiple compute nodes with three separate networks: vm data, external/public, and OpenStack management.In a QuickStart, or single-ip configuration, all of the public IP addresses are configured on an internal software bridge (specifically, an instance of [Open vSwitch](http://openvswitch.org/)). The IPs are able to access the outside world through the use of iptables masquerade rules (source NAT) that utilize the IP address of the host machine. You can also choose an “on-the-wire” configuration for your OpenStack public network, which requires a lot of routable IP addresses. **We recommend acquiring an IP address range that includes at least 24 addresses** if you would like to go with the latter configuration.After working with QuickStart, you may decide to deploy different variations of OpenStack -- for example, to try a VXLAN network instead of GRE, which is the default -- or you may want to try a more realistic deployment with more networks and machines. By following this guide, you can start simply and try progressively more complicated and powerful deployments. We'll begin with the default QuickStart Packstack configuration, then review how to change your deployment options to build a more powerful (and more complicated) environment.# Initial SetupFirst, download and install [CentOS 7, minimal ISO](https://www.centos.org/download/), or  [Red Hat 7, standard DVD ISO](https://access.redhat.com/downloads/), on every machine that will run Packstack or OpenStack. You can run services on the same machine as Packstack, or on separate machines. **NOTE:** There have been reports of problems using DHCP, so a static IP address is recommended.  **IMPORTANT:** If you configure a valid hostname of the form "a.b.c", then the hostname MUST be resolvable via your DNS server (i.e., it's not enough to just add the hostnames to */etc/hosts*). We have had success using a hostname in the form "a.b" (for example, "stack1.openstack") without having to configure DNS. If you are unable to configure DNS and/or unsure as to whether it would be necessary, then don't configure a hostname - just leave it as "localhost.localdomain". We recommend that you configure the root password as “default”, and that you add a user account named “manager” with the password "manager" for setup purposes. These instructions contain multiple references to the manager username/password combination.**Red Hat 7**If you are using Red Hat 7, you'll need a Red Hat Enterprise Linux Server subscription and RHEL OpenStack Platform subscription. (Free evals are available for 30 days). You should set up the subscription and repositories according to the instructions linked to below, **but don't run Packstack**. [Red Hat Getting Started instructions](https://access.redhat.com/products/red-hat-enterprise-linux-openstack-platform/get-started)Please note that the Red Hat doc instructs you to disable Network Manager and reboot\*, but don't mention that **you need to put your default gateway in */etc/sysconfig/network* before rebooting** (use the syntax shown below), or you will lose connectivity to your machine.```GATEWAY=1.2.3.254```\* at the time of this doc's creation# LicensingBefore running QuickStart, you'll need to place your BIG-IP licenses -- one per line -- in the file *.f5-onboard/conf/startup.licenses*.If you haven't already purchased licenses, we recommend using the options shown below.**Product Line** | **Product** | **Options**:---|:---|:---BIG-IP | F5-BIG-LTM-VE-5G-LIC | Best Bundle; 5gbps; Recycle; VE# QuickStart## OverviewThe instructions in this section will set up an OpenStack environment with F5 BIG-IP Virtual Edition using only one machine, with only one IP address. The `--quickstart` option encompasses the [ODK commands](#) shown below. ```odk-set-conf deployments odk-maas ext-net-cidr=10.99.0.0/16odk-set-conf deployments odk-maas ext-netmask=255.255.0.0odk-set-conf deployments odk-maas ext-address=10.99.1.1odk-set-conf deployments odk-maas ext-gateway=10.99.255.254odk-set-conf deployments odk-maas vnc-proxy-address=10.99.1.1odk-set-conf deployments odk-maas floating-start=10.99.2.1odk-set-conf deployments odk-maas floating-end=10.99.2.255odk-set-conf deployments odk-maas ext-data-net-start=10.99.3.1odk-set-conf deployments odk-maas ext-data-net-end=10.99.3.255odk-set-conf deployments odk-maas vlan-range=1400:1429odk-set-conf deployments odk-maas CONTROL_HOST=\`hostname -I\`odk-set-conf deployments odk-maas NETWORK_HOST=\`hostname -I\`odk-set-conf deployments odk-maas COMPUTE_HOST=\`hostname -I\`odk-openstack deploy --num-machines 1 --network-type gre --ext-net-topology combined --data-net-topology combined --ip-strategysingle --test --no-cleanup```In short, these commands do the following: -   Install, update, and configure repositories for OpenStack and Packstack packages. -   Apply a few patches for known issues. -   Set up the Packstack answer file for how to configure OpenStack. -   Run Packstack to install all OpenStack packages and configure them. -   Set up iptables to allow outbound access from the OpenStack internal bridge (10.99.0.0/16 on br-ex). -   Create an admin project/tenant with initial security settings. -   Create admin networks to support running BIG-IP. -   Upload BIG-IP VE 11.6.0 qcow image file. -   Create an instance flavor for BIG-IP. -   Launch a BIG-IP in the admin project, writing its license key in metadata. -   Retrieve the BIG-IP license from metadata, launches the BIG-IP and licenses it on startup. -   Install the F5 OpenStack LBaaSv1 plugin and configures it to use the new BIG-IP. -   Create a proj_1 project with a network and two VMs on a private network, each running a web server. -   Create a proj_2 project with a network and two VMs on a private network, each running a web server. -   Create a proj_3 project with a network and one VM on a private network and one VM on a shared network, each running a web server. -   Create a pool, monitor, and VIP to load-balance proj_1 VMs, then test the VIP. -   Create a pool, monitor, and VIP to load-balance proj_2 VMs, then test the VIP. -   Create a pool, monitor, and VIP to load-balance proj_3 VMs, then test the VIP.## Installation 1. Log in as **manager** and run the commands shown below. **NOTE:** Be sure to replace the IP address and password in this example as appropriate.```    $ scp <manager@10.144.65.66:quickstart.tgz> . # 1 GB file; password: manager    $ tar xvzf quickstart.tgz    $ su    # rpm -i odk-*.noarch.rpm f5-onboard-*.noarch.rpm    # odk-install    # reboot``` 2. Log back in, then:```    $ f5-onboard-setup    $ odk-openstack deploy --quickstart```The installation should take about an hour; the output should end with “TEST PASSED”.# Troubleshooting for Single Machine Configurations## Stop iptables**NOTE:**If you are using a Single IP configuration, skip this section.In a single-machine/single-network configuration, BIG-IP may not be able to acces the metadata server to retrieve the licenses. If this is the case, you need to run `systemctl stop iptables`.{% comment %}NEEDS ADDITIONAL INFORMATION --JP {% endcomment %}## Variations{% comment %}NEED TO VERIFY THIS SECTION APPLIES TO THIS USAGE. --JP{% endcomment %}You may want to try running PackStack with configurations other than the QuickStart defaults. **NOTE:** To use a variation *after* running QuickStart vanilla, you'll need a fresh install of CentOS or Red Hat.**NOTE:** Options are processed from left to right. Place parameters to the right of `--quickstart` to properly override the quickstart settings. ### Use VXLAN```odk-openstack deploy --quickstart --network-type vxlan```### Quickstart Diagram```odk-openstack deploy --num-machines 1 --network-type gre --ext-net-topology combined --data-net-topology combined --ip-strategy single --test --no-cleanup```### No Single-IP Diagram```odk-openstack deploy --num-machines 1 --network-type gre --ext-net-topology combined --data-net-topology combined --test --no-cleanup```### Multiple Machines```odk-set-conf deployments odk-maas CONTROL_HOST=10.144.65.43odk-set-conf deployments odk-maas NETWORK_HOST=10.144.65.44odk-set-conf deployments odk-maas COMPUTE_HOST=10.144.65.45odk-openstack deploy --network-type gre --ext-net-topology combined --data-net-topology combined --test --no-cleanup```### Separate Data Network```odk-set-conf deployments odk-maas CONTROL_HOST=10.144.65.43odk-set-conf deployments odk-maas NETWORK_HOST=10.144.65.44odk-set-conf deployments odk-maas COMPUTE_HOST=10.144.65.45odk-openstack deploy --network-type gre --ext-net-topology combined --test --no-cleanup```### No Single-IP```odk-set-conf deployments odk-maas CONTROL_HOST=10.144.65.43odk-set-conf deployments odk-maas NETWORK_HOST=10.144.65.44odk-set-conf deployments odk-maas COMPUTE_HOST=10.144.65.45odk-openstack deploy --network-type gre --test --no-cleanup```# What's Next?You should now have a one-machine, single-ip OpenStack environment. You can access the OpenStack GUI using the path *http://<ip_address\>/dashboard* and the credentials in the file *keystonerc_admin*, which is placed in the current directory.See also: [Exploring OpenStack](#).# Set Up Packstack with Multiple Machines / Multiple NetworksThis section explains how to create a more advanced configuration than that deployed by QuickStart. You can configure a NIC for OpenStack management for all nodes; a NIC for the data network for the network and compute nodes; and a NIC for the external network on the network and Packstack controller node. Alternatively, you can combine those networks into two, or to just one. **NOTE:** If you wish to test VLAN-based network virtualization, you'll need to configure VLAN support for the switches to which the OpenStack Data network NICs connect.According to the Packstack instructions, you must give each node a host name that's resolvable in DNS. We use names such as "pack-ctrl-4.Packstack", "node-services.Packstack", "node-compute-1.Packstack", and "node-network.Packstack", and populate them in the */etc/hosts* file on every host after install and reboot completes. You shouldn't need to populate the DNS server if you follow the same naming conventions.**Tips:** - If you are using a two-machine configuration, we recommend using the names "node-network.Packstack" and "node-compute-1.Packstack". - After first boot into CentOS or Red Hat, **login as root** on all machines.  - If you need to need to change NIC labels to match their expected usage,  do so in the */etc/udev/rules.d/70-persistent-net.rules* file; you'll need to change corresponding */etc/sysconfig/network-scripts* files to match the correct MAC addresses as well.  - **REBOOT** right away after you change udev, or you’ll have problems if you try to restart the network later. - There are several steps that require restarting network services. Because as lock-ups can occur if you restart the network over an SSH session, you may want to use a remote IPMI console session when making the configurations described in this section.## Configure the Host NamesOn all nodes, log in as root and edit */etc/hosts* to add the hostnames you will be using.**NOTE:** The IP addresses and names shown in this example are for instructional purposes only. Replace these as appropriate for your configuration.```vi /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain610.144.65.34 pack-ctrl-4 pack-ctrl-4.Packstack10.144.65.43 node-services node-services.Packstack10.144.65.44 node-network node-network.Packstack10.144.65.45 node-compute-1 node-compute-1.Packstack```## Connect the Data Network**If you are using the single-machine/single-network configuration** -- in other words, both data net and external net are combined with the management network (`--data-net-topology combined` `--ext-net-topology combined`) -- **skip this section**.On the network nodes and the compute nodes, configure an IP address on the NIC that will be used for the data network. Be sure to pick a unique IP for each host and set IPADDR accordingly. This is done in */etc/sysconfig/network-scripts/ifcfg-eth1* (substitute 'eth1' with the name of the NIC you're using for the data network):```vi /etc/sysconfig/network-scripts/ifcfg-enp4s0f0HWADDR=00:25:90:CA:A7:ECTYPE=EthernetNAME=enp4s0f0UUID=7736f978-0519-468f-8436-785e4a568d6eONBOOT=yesBOOTPROTO=staticIPADDR=10.30.30.1NETMASK=255.255.255.0[root@compute/network ~]# systemctl restart network```Later, we’ll move the IP address for the data network NIC to br-data (after Packstack creates br-data; see Tunneling, below). For now, you can use the IP to ping the other peers to ensure the data network is functional.### TunnelingPackstack utilizes a user-configured interface name to determine what IP address should be used as the tunnel endpoint. We recommend that you set up your tunnel on a data network **separate from the OpenStack management network**; if you do so, you'll need to set up a tunnel IP address that will communicate via a different physical interface than the one used for management traffic. **NOTE:** BIG-IP VE uses a “provider network” to access the tunnel network and OVS requires a bridge to implement the provider network. Place the tunnel endpoint on the OVS bridge so BIG-IP can access the tunnel network. As OVS is not yet installed at this point, we've temporarily placed the tunnel endpoint directly on the physical interface. Once OVS is installed, place the tunneling IP on the OVS bridge named br-data.## Update Software and Reboot**NOTE:** The instructions in this section are for CentOS 7. For Red Hat 7, set up the subscription and repositories according to the [Red Hat instructions](https://access.redhat.com/products/red-hat-enterprise-linux-openstack-platform/get-started), but **do not run Packstack**.  1. Copy F5’s [OpenStack Deployment Kit](#) and [OpenStack Onboard rpms](#) to `manager@<hostname>`. 2. On Packstack **(controller) node**, run all of the following commands as **root**.```    rpm -i odk-0.8.1-1.noarch.rpm    rpm -i f5-onboard-0.8.0-1.noarch.rpm    odk-install``` 3. Run the following commands on **all hosts except the controller**.  **NOTE:** The `odk-install` command did this and a bit more for you on the controller machine.```    systemctl disable NetworkManager    echo GATEWAY=10.144.65.62 << /etc/sysconfig/network    sed -i 's/42, 55, 56/42,/' /usr/lib/python2.7/site-packages/urlgrabber/grabber.py    yum install -y <https://rdo.fedorapeople.org/rdo-release.rpm>    yum install -y deltarpm    yum update -y```**NOTE:** The `sed` command above fixes a [bug in the file grabber that yum uses](https://bugzilla.redhat.com/show_bug.cgi?id=1099101) that was active at the time this doc was written. If the bug is no longer active, the `sed` line is not necessary. ## Configure the ODK Toolkit 1. Log in to the Packstack controller as 'manager' (password: manager).```mkdir –p ~/.f5-onboard/images/patchedscp <manager@10.144.65.66:.f5-onboard/images/patched/BIGIP-11.6.0.0.0.401-OpenStack.qcow2> ~/.f5-onboard/images/patchedpassword: manager``` 2. Put 4 VE licenses (Best, 5G, Recyclable) in *config/startup.licenses* if you haven't already done so. 3. Run `f5-onboard-setup`. 4. Configure the values below as appropriate for your routable IP ranges. **NOTES:**  - **Do not just copy the commands below.**  - You must tell Packstack the IP address of each node to use (CONTROL_HOST, NETWORK_HOST, COMPUTE_HOST), so you'll need to replace the IP addresses shown here with your own valid IPs.  - For a three-machine setup, run Packstack on the CONTROL_HOST and use different values for CONTROL_HOST and NETWORK_HOST.  - For a two-machine setup, run Packstack on the CONTROL_HOST and use the same value for CONTROL_HOST and NETWORK_HOST.```odk-set-conf deployments odk-maas ext-net-cidr=10.144.64.0/24odk-set-conf deployments odk-maas ext-address=10.144.64.31odk-set-conf deployments odk-maas ext-netmask=255.255.255.0odk-set-conf deployments odk-maas ext-gateway=10.144.64.254odk-set-conf deployments odk-maas floating-start=10.144.64.32odk-set-conf deployments odk-maas floating-end=10.144.64.49odk-set-conf deployments odk-maas vnc-proxy-address=10.144.64.31odk-set-conf deployments odk-maas vlan-range=1400:1429odk-set-conf deployments odk-maas ext-port=eno2odk-set-conf deployments odk-maas data-port=enp4s0f0odk-set-conf deployments odk-maas deployer=Packstackodk-set-conf deployments odk-maas CONTROL_HOST=10.144.65.43odk-set-conf deployments odk-maas NETWORK_HOST=10.144.65.44odk-set-conf deployments odk-maas COMPUTE_HOST=10.144.65.45```# Deploy OpenStack 1. Log in to the **Packstack controller host**. 2. Start the OpenStack deployment script.         **NOTE:** If you are using a two-machine setup, you may have trouble maintaining a network connection to the script when you change your default route on the network node (which is where you will be running the odk and Packstack). For this reason, we recommend running `odk-openstack deploy` in [Screen](https://www.gnu.org/software/screen/); this allows you to detach the login session, restart the network, reconnect through the external network, and then resume the session.    To install screen:```    su    yum install screen -y    exit    screen –h 200000 –S test``` 3. Start the OpenStack deployment:```    odk-openstack deploy --network-type gre --test \\ deploys the default configuration    odk-openstack deploy --data-net-topology combined --ext-net-topology combined --network-type gre --test \\ deploys a single network topology```    After Packstack deploys OpenStack, you'll need to complete some networking steps before proceeding with testing. There are also steps required to configure load balancing. These steps are described in the next sections. You will be prompted to press return when you have completed them.**NOTE:** The `odk-openstack deploy` command implements various workarounds to fix bugs and other shortcomings. See [ODK OpenStack Deployment Workarounds](#) for details.# Finish Network Configuration**If you are using the single-machine/single-network configuration** -- in other words, both data net and external net are combined with the management network (`--data-net-topology combined` `--ext-net-topology combined`) -- **proceed directly to the “Single Machine Fixes” section**.## Set up Network Bridges on Network Node1. On the **network node** only, configure the IP address on the external network in */etc/sysconfig/network-scripts/ifcfg-br-ex*.```vi /etc/sysconfig/network-scripts/ifcfg-br-ex# Contents: (don’t include this line)DEVICE=br-exDEVICETYPE=ovsTYPE=OVSBridgeBOOTPROTO=staticIPADDR=10.44.64.31NETMASK=255.255.255.0ONBOOT=yes```2. Add the physical interface for the external network to the bridge:```[root@network ~]# vi /etc/sysconfig/network-scripts/ifcfg-eno2HWADDR=00:25:90:7B:C8:13NAME=eno2UUID=eb76065b-8207-467e-8ef6-6be2f633b19bONBOOT=yesDEVICETYPE=ovsBOOTPROTO=noneTYPE=OVSPortOVS_BRIDGE=br-ex```3. On the network node, configure the IP address for the data network which can be used for tunneling. (**For configurations where the data network is not separate, such as single network configurations, skip this step**). Be sure to change IPADDR so that there is a unique IP for each host:```[root@network ~]# vi /etc/sysconfig/network-scripts/ifcfg-br-dataONBOOT=yesPEERDNS=noNM_CONTROLLED=noNOZEROCONF=yesDEVICE=br-dataDEVICETYPE=ovsTYPE=OVSBridgeBOOTPROTO=staticOVSBOOTPROTO=staticIPADDR=10.30.30.1NETMASK=255.255.255.0```## Change Network Host Default GatewayIn some scenarios, it may be necessary to move the default route on the **network host** from the management NIC to the external network, so VMs can route to the Internet or the local data center (for example, if you used the management NIC to get to the Internet for updates). Presumably, both NICs can have default gateways, but as this has caused problems in testing we recommend reconfiguring the gateway. This is done by changing the GATEWAY line in */etc/sysconfig/network* to the default route on the public/external network.```[root@network ~]# vi /etc/sysconfig/network[root@network ~]# systemctl restart network```## Compute Node Data Network Bridge1. Configure the tunnel IP address on the data network bridge.**NOTE:** Be sure to change IPADDR so that there is a unique IP for each host.```[root@compute ~]# vi /etc/sysconfig/network-scripts/ifcfg-br-dataDEVICE=br-dataDEVICETYPE=ovsTYPE=OVSBridgeBOOTPROTO=staticIPADDR=10.30.30.2NETMASK=255.255.255.0ONBOOT=yes```2. Remove the address from the physical interface and put the interface in the bridge.```[root@compute ~]# vi /etc/sysconfig/network-scripts/ifcfg-enp4s0f0DEVICE=enp4s0f0DEVICETYPE=ovsTYPE=OVSPortOVS_BRIDGE=br-dataONBOOT=yesBOOTPROTO=none[root@compute ~]# systemctl restart network```3. Verify the connection (this should work within 30 seconds or so).```[root@compute ~]# ping 10.30.30.1[root@network ~]# systemctl restart neutron-openvswitch-agent```# Workarounds {% comment %} PLACE THESE ELSEWHERE? --JP {% endcomment %}## Single-IP External Bridge and IPTables Configuration**NOTE:** This section only applies to the single-ip configuration.To set up the br-ex bridge, OVS, and IP tables to operate with OpenStack with only a single host IP address, run `/usr/libexec/odk/openstack/packstack/setup-single-ip.sh`.See also: [ODK OpenStack Deployment Workarounds]({% "/ODK_OpenStack_Deployment_Workarounds#Single_IP_Setup" | prepend: site.baseurl | prepend: site.url %})## LBaaS BIG-IP PreparationRun this command:`/usr/libexec/f5-onboard/lbaas/setup-lbaas.sh`See [Workarounds](#) for details.# Optional Testing StepsThe F5 OpenStack Toolkit provides scripts for deploying OpenStack with F5 technologies and running tests. To run the tests provided with the toolkit, complete the following steps.## Set up Direct Access to Floating IPs for TestingIf you are running tests against the OpenStack deployment and you have set up a local, non routable network and you need to access that network from a test client machine, then you should setup an interface on the test machine to access the floating ip range of the external network of the OpenStack router/network gateway host. Alternatively, if you can route to that network, you may not need to setup this interface.This would be done on the **Packstack controller node**, for example in */etc/sysconfig/network-scripts/ifcfg-eth2*:```DEVICE=eth2HWADDR=00:25:90:CA:A7:8ATYPE=EthernetUUID=4c99b4c5-86fe-4540-9a7f-765d95bcbc7fONBOOT=yesBOOTPROTO=staticIPADDR=10.144.64.30NETMASK=255.255.255.0NAME="System eth2"systemctl restart networkping 10.144.64.31 # the network host external ip.```Ping may take 30 seconds or so to succeed.# Known Issues## Lost Connectivity after RebootIf you reboot an OpenStack node and have networking trouble, run this command:`systemctl restart network`.On the network and compute nodes, run this command:`systemctl restart neutron-openvswitch-agent`### VLAN Trunk Access Workaround - Alternatives**NOTE:** This issue only applies to the deployment scenario where a special procedure has been used to grant BIG-IP Virtual Edition running on OpenStack Nova access to tenant networks via a VLAN trunk.If a Tap interface corresponding to a VE interface is moved from the integration bridge (br-int) to the data bridge (br-data) then packets may have invalid checksums when there is communication between a BIG-IP VE and a VM on the same Compute Host. Usually the tap interface is moved to give BIG-IP access to all VLANs. However, these tagged packets appear to cause problems with checksums. There are three potential workarounds:1. Upgrade the kernel on the Compute NodeThe underlying problem is associated with the installed 2.6 kernel on the compute node. Later kernel versions do not have the problem. The natural solution is to update the kernel to the one that has the appropriate fix. This is the default workaround which is provided in previous instructions.`yum install -y centos-release-xen && yum update -y --disablerepo=\* --enablerepo=Xen4CentOS kernel && reboot`2. Dedicate the compute machine to BIG-IP VEs.The problem only occurs when BIG-IP VE is talking to tenant VMs on the same compute host. You would need to create a Nova availability zone dedicated to BIG-IP VEs and other zone(s) for non- BIG-IP VMs and ensure that all VMs are deployed to the right compute nodes.3. Dedicate a NIC to BIG-IP VE If the packets from the tenant VM go out a real NIC, go to the switch, and then come back through another NIC dedicated to VE, then the checksums are OK. The following steps explain how to dedicate a NIC to BIG-IP VE.  -  Create an OVS bridge for the BIG-IPs      `ovs-vsctl add-br br-bigips`  -  Add the dedicated NIC to the data network bridge      `ovs-vsctl add-port br-bigips eth3`  -  Add the BIG-IP VE tap interface to the br-bigips bridge instead of br-data.      `ovs-vsctl add-port br-bigips tap8369a267-c2`